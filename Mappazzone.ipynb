{"cells":[{"cell_type":"markdown","metadata":{"id":"axHQYI3joBAD"},"source":["# Earthquake Data Analysis\n","\n","### Description\n","\n","The catalog includes the magnitude, time of occurrence (s), and 3D coordinates (m) of earthquakes in about 20 years of recording in South California. Coordinates were converted from latitude, longitude, and depth of events in a seismic catalog. Magnitudes should be within the range $[0,8]$.\n","\n","* **Waiting time (t)**: time interval between an event and the next one in the sequence.\n","* **Distance (r)**: Eucledian 3D distance between events. (each 3D set of coordinates refers to the hypocenter, i.e. the point triggering the slip in a fault that forms the earthquake)\n","\n","\n","### Assignments\n","\n","1. Deduce what is the variable in each column of the catalog.\n","2. Visualize the process in space and/or time with suitable time series and/or 3D visualizations of the hypocenters. For instance, plot a space variable (a single coordinate or a nice linear combination of coordinates) as a function of time.\n","3. Compute the distribution $P_m(t)$ of waiting times for events of magnitude m or above (i.e. do not consider events below $m$). In shaping the bin sizes, take into account that this distribution is expected to have a power-law decay with time (e.g $\\sim 1/t$), and that a power-law is well visualized in log-log scale. Do this analysis for many values of $m$, say $m=2,3,4,5$.\n","4. Compute the distribution $P_m(r)$ of the distance between an event and the next one, considering earthquakes of magnitude m or above. Also here make a clever choice for the bin sizes and try several values of $m$.\n","5. Compute the distribution $P_{m,R}(t)$ of waiting times for events of magnitude $m$ or above, which are separated by at most a distance $r<R$, for different values of m and $R$. (In this statistics, if the following event is farther than $R$, skip the $t$ and go to the next pair)\n","6. Eventually note if, from the analysis of the previous points, there emerges a scaling picture. Is there a suitable rescaling that collapses distributions for various $m$ (and eventually $R$ if point 5 is considered) on a single curve?\n","\n","### Datasets\n","\n","* column 1: index of the event\n","* column 2: index of the previous event that triggered it (defined with a given algorithm), -1 if no ancestor is found\n","* column 3: time (seconds) from 0:00 of Jan.1st, 1982\n","* column 4: magnitude\n","* columns 5, 6, and 7: 3D coordinates (meters) of the earthquake hypocenter, i.e. of the point from where it started. These Euclidean coordinates are derived from latitude, longitude and depth.\n","\n","Joining each event to that with the index of the second column (if not -1), there emerges a set of causal trees.\n","\n","\n","### Contact\n","* Marco Baiesi <marco.baiesi@unipd.it>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j9T7DHoSoBAM"},"outputs":[],"source":["import pandas as pd\n","\n","data = 'SouthCalifornia-1982-2011_Physics-of-Data.dat'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1771,"status":"ok","timestamp":1706104418455,"user":{"displayName":"Ginevra Beltrame","userId":"01658554142306018550"},"user_tz":-60},"id":"h5pY4JPooJhW","outputId":"dcecca2c-30ce-44c1-8c4d-b9c0fc89fad1"},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/content/drive')\n","#filepath = '/content/drive/MyDrive/LCP_project/'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1706104418455,"user":{"displayName":"Ginevra Beltrame","userId":"01658554142306018550"},"user_tz":-60},"id":"jynXRx7UoBAQ","outputId":"f5291bd9-1d47-4599-b2cf-08b0a6ea05be"},"outputs":[],"source":["#df = pd.read_csv(filepath + data, sep = ' ', names = ['Index', 'Prev event', 'Time', 'Magnitude', 'x', 'y', 'z'])\n","df = pd.read_csv(data, sep = ' ', names = ['Index', 'Prev_event', 'Time', 'Magnitude', 'x', 'y', 'z'])\n","\n","df.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1706104498187,"user":{"displayName":"Ginevra Beltrame","userId":"01658554142306018550"},"user_tz":-60},"id":"c0riGxsOwJFP","outputId":"bb948092-286f-49dd-f9ed-6101e6fb8d21"},"outputs":[],"source":["df.tail(5)\n","df"]},{"cell_type":"markdown","metadata":{},"source":["# Graphical Part"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":730},"executionInfo":{"elapsed":25901,"status":"ok","timestamp":1706105823000,"user":{"displayName":"Ginevra Beltrame","userId":"01658554142306018550"},"user_tz":-60},"id":"oh31-DiuoBAT","outputId":"97106895-e5cf-42ad-c01b-8efdd9182146"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","fig = plt.figure(figsize=(18,10))\n","\n","ax1 = fig.add_subplot(2, 3, 1, projection='3d')\n","scatter1 = ax1.scatter(df['x'], df['y'], df['z'], c=df['Time'], cmap='viridis', marker='.')\n","ax1.set_xlabel('x')\n","ax1.set_ylabel('y')\n","ax1.set_zlabel('z')\n","fig.colorbar(scatter1, label='Time', shrink=0.7)\n","\n","ax2 = fig.add_subplot(2, 3, 2)\n","scatter2 = ax2.scatter(df['x'], df['y'], c=df['z'], cmap='inferno', marker='.')\n","ax1.set_xlabel('x')\n","ax1.set_ylabel('y')\n","fig.colorbar(scatter2, label='Depth', shrink=0.7)\n","\n","ax3 = fig.add_subplot(2, 3, 3)\n","scatter3 = ax3.scatter(df['x'], df['y'], c=df['Time'], cmap='viridis', marker='.')\n","fig.colorbar(scatter3, label='Time', shrink=0.7)\n","\n","ax4 = fig.add_subplot(2, 3, 4, projection='3d')\n","scatter4 = ax4.scatter(df['x'], df['y'], df['z'], c=df['Time'], cmap='viridis', marker='.')\n","fig.colorbar(scatter4, label='Time', shrink=0.7)\n","\n","ax5 = fig.add_subplot(2, 3, 5)\n","scatter5 = ax5.scatter(df['x'], df['y'], c=df['z'], cmap='inferno', marker='.')\n","fig.colorbar(scatter5, label='Depth', shrink=0.7)\n","\n","ax6 = fig.add_subplot(2, 3, 6)\n","scatter6 = ax6.scatter(df['x'], df['y'], c=df['Time'], cmap='viridis', marker='.')\n","fig.colorbar(scatter6, label='Time', shrink=0.7)\n","\n","# andamento chiaro della dipendenza della depth da longitude e latitude, inefficacia del primo plot perchè non c'è una\n","# dipendenza temporale definita dalla posizione dell'ipocentro"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import math\n","import plotly.express as px\n","import matplotlib as mpl\n","from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n","import seaborn as sns\n","import numpy.linalg as la"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# AGGIUNTA COLONNE PER I DATI AGGIUNTIVI: Waiting time, Distance, lat, lon, dep\n","df['Waiting time prev'] = df['Index']\n","df['Distances prev'] = df['Index']\n","df['Waiting time'] = df['Index']\n","df['Distances'] = df['Index']\n","\n","for i in range(np.shape(df)[0]):\n","  if df['Prev_event'][i] == -1:\n","    Time_1 = df['Time'][i]\n","    Distance_1 = np.array([df['x'][i], df['y'][i], df['z'][i]])\n","  elif df['Prev_event'][i] > -1:\n","    Time_1 = df['Time'][df['Prev_event'][i]]\n","    Distance_1 = np.array([df['x'][df['Prev_event'][i]], df['y'][df['Prev_event'][i]], df['z'][df['Prev_event'][i]]])\n","\n","  df['Waiting time prev'][i] = df['Time'][i] - Time_1\n","  df['Distances prev'][i] = math.sqrt(np.sum((np.array([df['x'][i], df['y'][i], df['z'][i]]) - Distance_1)**2))\n","\n","\n","for i in range(np.shape(df)[0]):\n","  if df['Index'][i] == 0:\n","    Time_1 = df['Time'][i]\n","    Distance_1 = np.array([df['x'][i], df['y'][i], df['z'][i]])\n","  elif df['Index'][i] > -0:\n","    Time_1 = df['Time'][i-1]\n","    Distance_1 = np.array([df['x'][i-1], df['y'][i-1], df['z'][i-1]])\n","\n","  df['Waiting time'][i] = df['Time'][i] - Time_1\n","  df['Distances'][i] = math.sqrt(np.sum((np.array([df['x'][i], df['y'][i], df['z'][i]]) - Distance_1)**2))\n","\n","R = 6371000 # m\n","df['r'] = df['Index']\n","for i in range(np.shape(df)[0]):\n","  df['r'][i] = (df['x'][i]**2 + df['y'][i]**2 + df['z'][i]**2)**0.5\n","\n","df['lat'] = np.arcsin(df['z'] / df['r'])*180/math.pi\n","df['lon'] = np.arctan2(df['y'], df['x'])*180/math.pi\n","df['dep'] = df['r'] - R\n","\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = plt.figure(figsize=(16,5))\n","\n","ax1 = fig.add_subplot(1, 3, 1, projection='3d')\n","scatter1 = ax1.scatter(df['x'], df['y'], df['z'], c=df['dep'], cmap='inferno_r', marker='.')\n","ax1.set_xlabel('x')\n","ax1.set_ylabel('y')\n","ax1.set_zlabel('z')\n","ax1.view_init(0,30)\n","fig.colorbar(scatter1, label='depth', shrink=0.5)\n","\n","ax2 = fig.add_subplot(1, 3, 2)\n","scatter2 = ax2.scatter(df['x'], df['y'], c=df['dep'], cmap='inferno_r', marker='.')\n","ax2.set_xlabel('x')\n","ax2.set_ylabel('y')\n","ax2.set_aspect(aspect=1)\n","fig.colorbar(scatter2, label='depth', shrink=0.7)\n","\n","ax3 = fig.add_subplot(1, 3, 3, projection='3d')\n","scatter3 = ax3.scatter(df['x'], df['y'], df['z'], c=df['dep'], cmap='inferno_r', marker='.')\n","ax3.set_xlabel('x')\n","ax3.set_ylabel('y')\n","ax3.set_zlabel('z')\n","ax3.view_init(0,150)\n","fig.colorbar(scatter3, label='depth', shrink=0.5)\n","\n","plt.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = plt.figure(figsize=(16,5))\n","\n","ax1 = fig.add_subplot(1, 3, 1, projection='3d')\n","scatter1 = ax1.scatter(df['lon'], df['lat'], df['dep'], c=df['dep'], cmap='inferno_r', marker='.')\n","ax1.set_xlabel('longitude')\n","ax1.set_ylabel('latitude')\n","ax1.set_zlabel('depth')\n","ax1.view_init(20,90)\n","fig.colorbar(scatter1, label='depth', shrink=0.5)\n","\n","ax2 = fig.add_subplot(1, 3, 2)\n","scatter2 = ax2.scatter(df['lon'], df['lat'], c=df['dep'], cmap='inferno_r', marker='.')\n","ax2.set_xlabel('longitude')\n","ax2.set_ylabel('latitude')\n","ax2.set_aspect(aspect=1)\n","fig.colorbar(scatter2, label='depth', shrink=0.7)\n","\n","df_mag4 = df[df['Magnitude'] > 4]\n","ax3 = fig.add_subplot(1, 3, 3, projection='3d')\n","scatter3 = ax3.scatter(df_mag4['lon'], df_mag4['lat'], df_mag4['dep'], c=df_mag4['dep'], cmap='inferno_r', marker='.')\n","ax3.set_xlabel('longitude')\n","ax3.set_ylabel('latitude')\n","ax3.set_zlabel('depth')\n","ax3.set_title('Magnitude > 4')\n","ax3.view_init(20,90)\n","fig.colorbar(scatter3, label='depth', shrink=0.5)\n","\n","plt.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = plt.figure(figsize=(16,5))\n","\n","ax1 = fig.add_subplot(1, 3, 1, projection='3d')\n","scatter1 = ax1.scatter(df['x'], df['y'], df['z'], c=np.log(df['Waiting time']), cmap='viridis', marker='.')\n","ax1.set_xlabel('x')\n","ax1.set_ylabel('y')\n","ax1.set_zlabel('z')\n","ax1.view_init(0,30)\n","fig.colorbar(scatter1, label='Waiting time log', shrink=0.5)\n","\n","ax2 = fig.add_subplot(1, 3, 2)\n","scatter2 = ax2.scatter(df['x'], df['y'], c=np.log(df['Waiting time']), cmap='viridis', marker='.')\n","ax2.set_xlabel('x')\n","ax2.set_ylabel('y')\n","ax2.set_aspect(aspect=1)\n","fig.colorbar(scatter2, label='Waiting time log', shrink=0.7)\n","\n","ax3 = fig.add_subplot(1, 3, 3, projection='3d')\n","scatter3 = ax3.scatter(df['x'], df['y'], df['z'], c=df['Time'], cmap='viridis', marker='.')\n","ax3.set_xlabel('x')\n","ax3.set_ylabel('y')\n","ax3.set_zlabel('z')\n","ax3.view_init(0,30)\n","fig.colorbar(scatter3, label='Time', shrink=0.5)\n","\n","plt.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = plt.figure(figsize=(16,5))\n","\n","ax1 = fig.add_subplot(1, 3, 1, projection='3d')\n","scatter1 = ax1.scatter(df['lon'], df['lat'], df['dep'], c=np.log(df['Waiting time']), cmap='viridis', marker='.')\n","ax1.set_xlabel('longtude')\n","ax1.set_ylabel('latitude')\n","ax1.set_zlabel('depth')\n","ax1.view_init(20,90)\n","fig.colorbar(scatter1, label='Waiting time log', shrink=0.5)\n","\n","ax2 = fig.add_subplot(1, 3, 2)\n","scatter2 = ax2.scatter(df['lon'], df['lat'], c=np.log(df['Waiting time']), cmap='viridis', marker='.')\n","ax2.set_xlabel('longitude')\n","ax2.set_ylabel('latitude')\n","ax2.set_aspect(aspect=1)\n","fig.colorbar(scatter2, label='Waiting time log', shrink=0.7)\n","\n","ax3 = fig.add_subplot(1, 3, 3, projection='3d')\n","scatter3 = ax3.scatter(df['lon'], df['lat'], df['dep'], c=df['Time'], cmap='viridis', marker='.')\n","ax3.set_xlabel('longitude')\n","ax3.set_ylabel('latitude')\n","ax3.set_zlabel('depth')\n","ax3.view_init(20,90)\n","fig.colorbar(scatter3, label='Time', shrink=0.5)\n","\n","plt.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = plt.figure(figsize=(16,10))\n","\n","ax1 = fig.add_subplot(2, 3, 1, projection='3d')\n","scatter1 = ax1.scatter(df['x'], df['y'], df['z'], c=df['Magnitude'], cmap='plasma', marker='.', vmin=np.min(df.Magnitude), vmax=np.max(df.Magnitude))\n","ax1.set_xlabel('x')\n","ax1.set_ylabel('y')\n","ax1.set_zlabel('z')\n","ax1.view_init(0,30)\n","fig.colorbar(scatter1, label='Magnitude', shrink=0.5)\n","\n","ax2 = fig.add_subplot(2, 3, 2)\n","scatter2 = ax2.scatter(df['x'], df['y'], c=np.log(df['Magnitude']), cmap='plasma', marker='.', vmin=np.min(np.log(df.Magnitude)), vmax=np.max(np.log(df.Magnitude)))\n","ax2.set_xlabel('x')\n","ax2.set_ylabel('y')\n","ax2.set_aspect(aspect=1)\n","fig.colorbar(scatter2, label='Magnitude log', shrink=0.7)\n","\n","df_mag3 = df[df['Magnitude'] > 3]\n","ax3 = fig.add_subplot(2, 3, 3, projection='3d')\n","scatter3 = ax3.scatter(df_mag3['x'], df_mag3['y'], df_mag3['z'], c=np.log(df_mag3['Magnitude']), cmap='plasma', marker='.', vmin=np.min(np.log(df.Magnitude)), vmax=np.max(np.log(df.Magnitude)))\n","ax3.set_xlabel('x')\n","ax3.set_ylabel('y')\n","ax3.set_zlabel('z')\n","ax3.view_init(0,30)\n","fig.colorbar(scatter3, label='Magnitude log > 3', shrink=0.5)\n","\n","df_mag4 = df[df['Magnitude'] > 4]\n","ax4 = fig.add_subplot(2, 3, 4, projection='3d')\n","scatter4 = ax4.scatter(df_mag4['x'], df_mag4['y'], df_mag4['z'], c=df_mag4['Magnitude'], cmap='plasma', marker='.', vmin=np.min(df.Magnitude), vmax=np.max(df.Magnitude))\n","ax4.set_xlabel('x')\n","ax4.set_ylabel('y')\n","ax4.set_zlabel('z')\n","ax4.view_init(0,30)\n","fig.colorbar(scatter4, label='Magnitude > 4', shrink=0.5)\n","\n","ax5 = fig.add_subplot(2, 3, 5)\n","scatter5 = ax5.scatter(df_mag4['x'], df_mag4['y'], c=np.log(df_mag4['Magnitude']), cmap='plasma', marker='.', vmin=np.min(np.log(df.Magnitude)), vmax=np.max(np.log(df.Magnitude)))\n","ax5.set_xlabel('x')\n","ax5.set_ylabel('y')\n","ax5.set_aspect(aspect=1)\n","fig.colorbar(scatter5, label='Magnitude log > 4', shrink=0.7)\n","\n","df_mag6 = df[df['Magnitude'] > 6]\n","ax6 = fig.add_subplot(2, 3, 6, projection='3d')\n","scatter6 = ax6.scatter(df_mag6['x'], df_mag6['y'], df_mag6['z'], c=df_mag6['Magnitude'], cmap='plasma', marker='o', alpha=0.8, vmin=np.min(df.Magnitude), vmax=np.max(df.Magnitude))\n","ax6.set_xlabel('x')\n","ax6.set_ylabel('y')\n","ax6.set_zlabel('z')\n","ax6.view_init(0,30)\n","fig.colorbar(scatter6, label='Magnitude log > 6', shrink=0.5)\n","\n","plt.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = plt.figure(figsize=(16,10))\n","\n","ax1 = fig.add_subplot(2, 3, 1, projection='3d')\n","scatter1 = ax1.scatter(df['lon'], df['lat'], df['dep'], c=df['Magnitude'], cmap='plasma', marker='.', vmin=np.min(df.Magnitude), vmax=np.max(df.Magnitude))\n","ax1.set_xlabel('longitude')\n","ax1.set_ylabel('latitude')\n","ax1.set_zlabel('depth')\n","ax1.view_init(20,90)\n","fig.colorbar(scatter1, label='Magnitude', shrink=0.5)\n","\n","ax2 = fig.add_subplot(2, 3, 2)\n","scatter2 = ax2.scatter(df['lon'], df['lat'], c=np.log(df['Magnitude']), cmap='plasma', marker='.', vmin=np.min(np.log(df.Magnitude)), vmax=np.max(np.log(df.Magnitude)))\n","ax2.set_xlabel('longitude')\n","ax2.set_ylabel('latitude')\n","ax2.set_aspect(aspect=1)\n","fig.colorbar(scatter2, label='Magnitude log', shrink=0.7)\n","\n","df_mag3 = df[df['Magnitude'] > 3]\n","ax3 = fig.add_subplot(2, 3, 3, projection='3d')\n","scatter3 = ax3.scatter(df_mag3['lon'], df_mag3['lat'], df_mag3['dep'], c=np.log(df_mag3['Magnitude']), cmap='plasma', marker='.', vmin=np.min(np.log(df.Magnitude)), vmax=np.max(np.log(df.Magnitude)))\n","ax3.set_xlabel('longitude')\n","ax3.set_ylabel('latitude')\n","ax3.set_zlabel('depth')\n","ax3.view_init(20,90)\n","fig.colorbar(scatter3, label='Magnitude log > 3', shrink=0.5)\n","\n","df_mag4 = df[df['Magnitude'] > 4]\n","ax4 = fig.add_subplot(2, 3, 4, projection='3d')\n","scatter4 = ax4.scatter(df_mag4['lat'], df_mag4['lon'], df_mag4['dep'], c=df_mag4['Magnitude'], cmap='plasma', marker='.', vmin=np.min(df.Magnitude), vmax=np.max(df.Magnitude))\n","ax4.set_xlabel('longitude')\n","ax4.set_ylabel('latitude')\n","ax4.set_zlabel('depth')\n","ax4.view_init(20,90)\n","fig.colorbar(scatter4, label='Magnitude > 4', shrink=0.5)\n","\n","ax5 = fig.add_subplot(2, 3, 5)\n","scatter5 = ax5.scatter(df_mag4['lon'], df_mag4['lat'], c=np.log(df_mag4['Magnitude']), cmap='plasma', marker='.', vmin=np.min(np.log(df.Magnitude)), vmax=np.max(np.log(df.Magnitude)))\n","ax5.set_xlabel('longitude')\n","ax5.set_ylabel('latitude')\n","ax5.set_aspect(aspect=1)\n","fig.colorbar(scatter5, label='Magnitude log > 4', shrink=0.7)\n","\n","df_mag6 = df[df['Magnitude'] > 6]\n","ax6 = fig.add_subplot(2, 3, 6, projection='3d')\n","scatter6 = ax6.scatter(df_mag6['lon'], df_mag6['lat'], df_mag6['dep'], c=df_mag6['Magnitude'], cmap='plasma', marker='o', alpha=0.8, vmin=np.min(df.Magnitude), vmax=np.max(df.Magnitude))\n","ax6.set_xlabel('longitude')\n","ax6.set_ylabel('latitude')\n","ax6.set_zlabel('depth')\n","ax6.view_init(20,90)\n","fig.colorbar(scatter6, label='Magnitude log > 6', shrink=0.5)\n","\n","plt.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_0 = df[df['Prev_event'] > 0]\n","df_1 = df[df['Prev_event'] == 0]\n","print(np.shape(df_0))\n","\n","fig = plt.figure(figsize=(16,5))\n","\n","ax1 = fig.add_subplot(1, 2, 1, projection='3d')\n","scatter1_1 = ax1.scatter(df_0['x'], df_0['y'], df_0['z'], c=df_0['Prev_event'], cmap='rainbow', marker='.')\n","scatter1_2 = ax1.scatter(df_1['x'], df_1['y'], df_1['z'], c='black', marker='.')\n","fig.colorbar(scatter1_1, label='Prev_event', shrink=0.5)\n","ax1.set_xlabel('x')\n","ax1.set_ylabel('y')\n","ax1.set_zlabel('z')\n","ax1.view_init(0,30)\n","\n","ax2= fig.add_subplot(1, 2, 2, projection='3d')\n","scatter2_1 = ax2.scatter(df_0['lon'], df_0['lat'], df_0['dep'], c=df_0['Prev_event'], cmap='rainbow', marker='.')\n","scatter2_2 = ax2.scatter(df_1['lon'], df_1['lat'], df_1['dep'], c='black', marker='.')\n","fig.colorbar(scatter2_1, label='Prev_event', shrink=0.5)\n","ax2.set_xlabel('longitude')\n","ax2.set_ylabel('latitude')\n","ax2.set_zlabel('depth')\n","ax2.view_init(20,90)\n","\n","plt.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ax1 = px.scatter_mapbox(df, lat=df.lat, lon=df.lon, color=df.Magnitude, width=600, height=500, opacity=0.5, color_continuous_scale='plasma',\n","                        center=dict(lat=32, lon=-117), zoom=4, title='Interactive map of the South California earthquakes',\n","                        mapbox_style='open-street-map')\n","ax1.show()\n","\n","ax2 = px.scatter_mapbox(df, lat=df.lat, lon=df.lon, color=df.dep, width=600, height=500, opacity=0.5, color_continuous_scale='inferno_r',\n","                        center=dict(lat=32, lon=-117), zoom=4, title='Interactive map of the South California earthquakes',\n","                        mapbox_style='open-street-map')\n","ax2.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df['Animation_frame'] = np.round(200*(df['Time']/df['Time'].max()))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ax1 = px.scatter_mapbox(df, lat=df.lat, lon=df.lon, color=df.Magnitude, width=600, height=500, opacity=1, color_continuous_scale='plasma', range_color=[df.Magnitude.min(), df.Magnitude.max()],\n","                        center=dict(lat=33.5, lon=-117), zoom=4, title='Interactive map of the South California earthquakes', animation_frame=df.Animation_frame,\n","                        mapbox_style='open-street-map')\n","ax1.show()\n","\n","ax2 = px.scatter_mapbox(df, lat=df.lat, lon=df.lon, color=df.dep, width=600, height=500, opacity=1, color_continuous_scale='inferno_r', range_color=[df.dep.min(), df.dep.max()],\n","                        center=dict(lat=33.5, lon=-117), zoom=4, title='Interactive map of the South California earthquakes', animation_frame=df.Animation_frame,\n","                        mapbox_style='open-street-map')\n","ax2.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sns.jointplot(df, x=df.lon, y=df.lat, kind='hist')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sns.kdeplot(df, x=df.lon, y=df.lat, fill=True, thresh=0, levels=10, cmap='rocket_r')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sns.jointplot(df, x=df.dep, y=df.Magnitude, kind='hist')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = plt.figure(figsize=(15,5))\n","\n","ax1 = fig.add_subplot(1,3,1)\n","ax1.plot(df.Time, df.Index, label='Time vs Index')\n","\n","ax2 = fig.add_subplot(1,3,2)\n","ax2.plot(df.Time, df.Magnitude, label='Time vs Magnitude')\n","\n","ax3 = fig.add_subplot(1,3,3)\n","ax3.plot(df.Time, df.Magnitude, label='Time vs Magnitude')"]},{"cell_type":"markdown","metadata":{},"source":["# PCA"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["PCA_array = np.array(df)[:, 4:7]\n","print(np.shape(PCA_array))\n","\n","C = np.cov(PCA_array.T)\n","sns.heatmap(C)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["U, spectrum, Vt = la.svd(PCA_array[:10000].T)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["l_svd = spectrum**2/(np.shape(df)[0]+1)\n","V_svd = U\n","\n","print('Autovalori\\t', l_svd/C.trace())\n","print('Autovettore\\t', V_svd[:,0])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["array_newbasis = np.array([la.solve(U, PCA_array[i, :]) for i in range(np.shape(PCA_array)[0])])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["np.shape(array_newbasis)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig = plt.figure(figsize=(15,5))\n","ax = fig.add_subplot(1,1,1, projection='3d')\n","\n","plt.scatter(array_newbasis[:,0], array_newbasis[:,1], array_newbasis[:,2])"]},{"cell_type":"markdown","metadata":{},"source":["# Resolution (beta)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":2675,"status":"ok","timestamp":1706106209358,"user":{"displayName":"Ada D'Iorio","userId":"09918381624555124017"},"user_tz":-60},"id":"L6D90nf11Wpr","outputId":"869da4c9-2a1f-4a53-ae9a-152233a4ebfe"},"outputs":[],"source":["#Versione 1\n","import numpy as np\n","\n","m = [2, 3, 4, 5]\n","\n","fig, ax = plt.subplots(1, 4, figsize = (14,7))\n","\n","for j, i in enumerate(m):\n","      df2 = df[df['Magnitude'] >= i].sort_values(by = 'Time')\n","      wt = np.diff(df2['Time'])\n","      wt[wt<1.e-5] = 1.e-6\n","      #x = np.logspace(np.log10(np.min(wt)), np.log10(np.max(wt)), 50)\n","      x = np.linspace(np.min(wt), np.max(wt), 75)\n","      print(np.min(x), np.max(x))\n","      print(np.min(wt), np.max(wt))\n","      \n","      ax[j].hist(wt, bins = x, edgecolor = 'black')\n","      #ax[j].set_xscale('log', base = 10)\n","      ax[j].set_yscale('log', base = 10)\n","      \n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Versione 2\n","\n","m = [2, 3, 4, 5]\n","\n","fig, ax = plt.subplots(1, 4, figsize = (14,7))\n","\n","for j, i in enumerate(m):\n","      df2 = df[df['Magnitude'] >= i].sort_values(by = 'Time')\n","      wt = df2[\"Time\"].diff().to_numpy()\n","      wt = wt[wt<1.e6]\n","      x = np.logspace(np.log10(10), np.log10(np.max(wt)), 50)\n","      #x = np.linspace(np.min(wt), np.max(wt), 75)\n","      print(np.min(x), np.max(x))\n","      print(np.min(wt), np.max(wt))\n","      \n","      ax[j].hist(wt, bins = x, edgecolor = 'black')\n","      ax[j].set_xscale('log', base = 10)\n","      ax[j].set_yscale('log', base = 10)\n","      \n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.plot(df['Time'], df['Index'])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#np.linalg.norm(x2-x1)\n","\n","fig, ax = plt.subplots(1, 4, figsize = (14,7))\n","\n","for j, i in enumerate(m):\n","      df2 = df[df['Magnitude'] >= i][['x', 'y', 'z']]\n","      coordinates = df2.to_numpy()\n","      dd = np.linalg.norm(np.diff(coordinates, axis = 0), axis = 1)\n","      print(dd.shape)\n","      \n","      #x = np.logspace(np.log10(np.min(wt)), np.log10(np.max(wt)), 50)\n","      x = np.linspace(np.min(dd), np.max(dd), 75)\n","      ax[j].hist(dd, bins = x, edgecolor = 'black')\n","      #ax[j].set_xscale('log', base = 10)\n","      #ax[j].set_yscale('log', base = 10)\n","      \n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Point 3. Distributions of waiting times"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy.stats import linregress\n","from scipy.stats import chisquare"]},{"cell_type":"markdown","metadata":{},"source":["First we define the functions we need for data analysis and plots."]},{"cell_type":"markdown","metadata":{},"source":["The `log_plot` function sets up all parameters we need for plotting histogram in log-log scale:\n","\n","* To select number of bins, we use the Scott formula: $$N_{\\text{bins}}\\simeq\\frac{3.49\\sigma}{n^{\\frac{1}{3}}}$$ where $\\sigma$ is the standard deviation and $n$ is the number of samples.  \n","To avoid having too few bins for future regressions, though, we choose a minimum number of bins equal to $10$.\n","\n","* We generate an equally logarithmically spaced set of points using `np.logspace()` specifying the number of bins we calculated before\n","\n","* After evaluating bin centers and bin widths we normalize the histogram in order to give a statistical meaning to the distribution.\n","\n","* We get rid of the empty bins in order for us to be able to evaluate the errors propagating the Poisson error of the unnormalized histogram.\n","\n","* The function returns the bin centers, the counts per bin and the errors (all in logarithmic scale)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def log_plot(feature):\n","    \n","    #Excluding zeros\n","    feature = feature[feature != 0]\n","    \n","    #Bin edges (in logarithmic scale)\n","    n_bins = max([np.histogram_bin_edges(np.log10(feature), bins = 'scott').shape[0] - 1, 10])\n","    \n","    x = np.logspace(np.log10(feature.min()), np.log10(feature.max()), base = 10, num = n_bins)\n","    \n","    #Histogram data\n","    hist = np.histogram(feature, bins = x)\n","    bin_centers = (hist[1][1:] + hist[1][:-1]) / 2\n","    bin_widths = hist[1][1:] - hist[1][:-1]\n","    \n","    #Normalization of the histogram\n","    norm = np.sum(hist[0])\n","    counts_normalized = hist[0] / (bin_widths * norm)\n","    \n","    #Errors\n","    errors = hist[0]\n","    \n","    #Clean of empty bins\n","    mask = (counts_normalized > 0)\n","    counts_normalized = counts_normalized[mask]\n","    bin_centers = bin_centers[mask]\n","    errors = errors[mask]\n","    errors = (np.log10(np.e) / (2 * errors)) * np.sqrt(errors)\n","    \n","    bins = np.log10(bin_centers)\n","    counts = np.log10(counts_normalized)\n","    \n","    return bins, counts, errors"]},{"cell_type":"markdown","metadata":{},"source":["As discussed later, we use `cut_tails` function to proper select the linearly distributed points (in log-log scale):\n","\n","* For the left side we first arbitraly drop off all data points a given threshold\n","\n","* Then, for both sides we recursively compare the pearson coefficient with the one we would obtain getting rid off of the extreme point: if the new value is better than the previous one we reject that point, otherwise we stop the algorithm.\n","\n","* The function returns bin centers, counts per bin, errors and the pearson coefficients list."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def cut_tails(b, c, e, threshold):\n","    \n","    c = c[b >= threshold]\n","    e = e[b >= threshold]\n","    b = b[b >= threshold] \n","    \n","    pearson = [0]\n","    \n","    while True:\n","        new_p = np.corrcoef(b[:-1], y = c[:-1])[0,1]\n","        if(new_p > pearson[-1] or len(b) <= 9):\n","            break\n","        b = b[:-1]\n","        c = c[:-1]\n","        e = e[:-1]\n","        pearson.append(new_p)\n","        \n","    while True:\n","        new_p = np.corrcoef(b[1:], y = c[1:])[0,1]\n","        if(new_p > pearson[-1] or len(b) <= 9):\n","            break\n","        b = b[1:]\n","        c = c[1:]\n","        e = e[1:]\n","        pearson.append(new_p)\n","        \n","    return b, c, e, pearson"]},{"cell_type":"markdown","metadata":{},"source":["The `statistic_plots` function allows us to perform a linear regression on the given feature and to evaluate the $\\chi^2$."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def statistic_plots(bins, counts, magnitudes, errors, feature):\n","    fit_res = []\n","    chis = []\n","\n","    fig, ax = plt.subplots(2, len(magnitudes), figsize = (14, 6))\n","\n","    for i, (x, y, m, e) in enumerate(zip(bins, counts, magnitudes, errors)):\n","\n","        #Linear regression\n","        slope, intercept, r, p, se = linregress(x, y)\n","        fit_res.append((slope, intercept, r, p, se))\n","        \n","        #Residuals\n","        residuals = y - (slope*x+intercept)\n","        \n","        #Chi square\n","        #chis.append(chisquare(y, f_exp = slope*x+intercept, ddof = 2))\n","\n","        #Plot\n","        x_axis = np.linspace(x.min(), x.max(), 100)\n","        ax[0,i].scatter(x, y, label=\"Data points\")\n","        ax[0,i].plot(x_axis, (slope * x_axis) + intercept, color = 'darkred', label = 'Fit')\n","        ax[0,i].set_ylabel(f\"$\\log(P_{m}({feature})$)\")\n","        ax[0,i].set_xlabel(f\"$\\log({feature})$\")\n","        ax[0,i].grid()\n","\n","        #Residual plot\n","        ax[1,i].errorbar(x, residuals, yerr = e, fmt = 'o', capsize = 2.5, label=\"Residual\")\n","        ax[1,i].hlines(0,x.min(), x.max(), color='darkred', label = 'Fit')\n","        ax[1,i].grid()\n","\n","    ax[0,-1].legend()\n","    ax[1,-1].legend()\n","    fig.suptitle('Linear regressions and residuals', fontsize = 18)\n","    plt.tight_layout()\n","    plt.show()\n","    #print(chis)\n","    \n","    return fit_res, chis"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Inizializing lists\n","magnitudes = [2, 3, 4, 5]\n","bins = []\n","counts = []\n","errors = []\n","\n","for i, m in enumerate(magnitudes):\n","    \n","    #Array of waiting times\n","    wt = np.array(df[df['Magnitude'] >= m][['Time']].sort_values('Time').diff())[1:]\n","    \n","    #Prepare data for plot\n","    b, c, e = log_plot(wt)\n","    bins.append(b)\n","    counts.append(c)\n","    errors.append(e)\n","    \n","    #Plot\n","    plt.scatter(10 ** b, 10 ** c, alpha = 0.75, label = f\"m $\\geq$ {m}\")\n","    plt.xscale('log', base = 10)\n","    plt.yscale('log', base = 10)\n","    \n","plt.xlabel('Waiting times ($s$)')\n","plt.ylabel('Probability density ($Hz$)')\n","plt.title('Distribution of waiting times for different magnitudes')\n","plt.legend()\n","plt.grid()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pearson_list = []\n","\n","for i, m in enumerate(magnitudes):\n","    \n","    bins[i], counts[i], errors[i], pearson = cut_tails(bins[i], counts[i], errors[i], threshold = 2)\n","    pearson_list.append(pearson)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fit_res, chis = statistic_plots(bins, counts, magnitudes, errors, 'wt')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["bins   = []\n","counts = []\n","errors = []\n","\n","for i, m in enumerate(magnitudes):\n","      #Array of siatcnes\n","      df2 = df[df['Magnitude'] >= m].sort_values('Time')[['x', 'y', 'z']]\n","      coordinates = df2.to_numpy()\n","      dd = np.linalg.norm(np.diff(coordinates, axis = 0), axis = 1)\n","      \n","      #Prepare data for plot\n","      b, c, e = log_plot(dd)\n","      bins.append(b)\n","      counts.append(c)\n","      errors.append(e)\n","      \n","      #Plot\n","      plt.scatter(10 ** b, 10 ** c, alpha = 0.75, label = f\"m $\\geq$ {m}\")\n","      plt.xscale('log', base = 10)\n","      plt.yscale('log', base = 10)\n","      \n","plt.xlabel('Distances ($m$)')\n","plt.ylabel('Probability density ($m^{-1}$)')\n","plt.title('Distribution of distances for different magnitudes')\n","plt.legend()\n","plt.grid()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pearson_list = []\n","\n","for i, m in enumerate(magnitudes):\n","    \n","    bins[i], counts[i], errors[i], pearson = cut_tails(bins[i], counts[i], errors[i], threshold = 2)\n","    pearson_list.append(pearson)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fit_res, chis = statistic_plots(bins, counts, magnitudes, errors, 'dd')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["magnitudes = [2, 3, 4]\n","Radii = [10000, 100000, 1000000]\n","\n","def get_Pmr(df, m, R): #m, R parameters given by the user\n","    \n","    dfm = df[df['Magnitude']>= m].sort_values('Time')[['Time', 'x', 'y', 'z']]\n","    \n","    #Evaluate the distance between one event and the next one \n","    coordinates = dfm.to_numpy()\n","    dd = np.linalg.norm(np.diff(coordinates, axis = 0), axis = 1)\n","    dd = np.insert(dd, 0, 0)\n","    \n","    dfm['Rel_distance'] = dd\n","    dfmr = dfm[dfm['Rel_distance'] <= R].sort_values('Time') #select by distance \n","    \n","    wt = np.array(dfmr['Time'].diff())[1:]\n","    \n","    return dfmr, dd, wt\n","\n","bins   = [[] for _ in range(len(Radii))]\n","counts = [[] for _ in range(len(Radii))]\n","errors = [[] for _ in range(len(Radii))]\n","\n","for i, m in enumerate(magnitudes):\n","    index = 0\n","    fig, ax = plt.subplots(1, len(Radii), figsize = (14,5))\n","    \n","    for j, radius in enumerate(Radii):\n","        dfmr, dd, wt = get_Pmr(df, m, radius)\n","        \n","        b, c, e = log_plot(wt)\n","        bins[j].append(b)\n","        counts[j].append(c)\n","        errors[j].append(e)\n","        \n","        ax[index].scatter(10 ** b, 10 ** c, edgecolor = 'black', marker = '.')\n","        ax[index].set_title(f'Histogram for m $\\geqslant$ {m} and R $\\leqslant$ {radius}')\n","        ax[index].set_yscale('log', base = 10)\n","        ax[index].set_xscale('log', base = 10)\n","        \n","        ax[index].set_ylabel(f\"$\\log(P_{m}(wt)$)\")\n","        ax[index].set_xlabel(f\"$\\log(wt)$\")\n","        ax[index].grid()\n","        \n","        index += 1\n","\n","    plt.tight_layout()\n","    \n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pearson_list = []\n","\n","for i, m in enumerate(magnitudes):\n","    for j, radius in enumerate(Radii):\n","        bins[j][i], counts[j][i], errors[j][i], pearson = cut_tails(bins[j][i], counts[j][i], errors[j][i], threshold = 2)\n","        pearson_list.append(pearson)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for j, radius in enumerate(Radii):\n","\n","    fit_res, chis = statistic_plots(bins[j], counts[j], magnitudes, errors[j], 'wt')"]},{"cell_type":"markdown","metadata":{},"source":["# Tree structure"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df['Fol event'] = [[] for _ in range(len(df))]\n","\n","for i in df['Index']:\n","    if df['Prev_event'][i] > -1:\n","        df['Fol event'][df['Prev_event'][i]].append(i)\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tree = px.treemap(data_frame=df[df['Index'] < 10], parents=df['Prev event'][df['Index'] < 10])\n","tree.show()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
